{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381994a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import statistics\n",
    "from natsort import natsorted, ns\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GINConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_two(Node_class, Edge_indices, n):\n",
    "    F_vec = []\n",
    "    for i in range(n):\n",
    "        #print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(n-1)), end='', flush=True)\n",
    "        node_F = []\n",
    "        list_out = []\n",
    "        list_In = []\n",
    "        S_nbd_out = []\n",
    "        S_nbd_in = []\n",
    "        for edge in Edge_indices:\n",
    "            src, dst = edge\n",
    "            if src == i:\n",
    "                list_out.append(label[dst])\n",
    "                for edge_2 in Edge_indices:\n",
    "                    src_2, dst_2 = edge_2\n",
    "                    if src_2 == dst and src_2 != dst_2:\n",
    "                        S_nbd_out.append(label[dst_2])\n",
    "\n",
    "        #print(list_out)\n",
    "        #print(list_In)\n",
    "        for d in Node_class:\n",
    "            count = 0\n",
    "            count_in = 0\n",
    "            \n",
    "            for node in list_out:\n",
    "                if Node_class[node] == d:\n",
    "                    count += 1\n",
    "            node_F.append(count)\n",
    "\n",
    "        for d in Node_class:\n",
    "            count_S_out = 0\n",
    "            count_S_in = 0\n",
    "            for node in S_nbd_out:\n",
    "                if Node_class[node] == d:\n",
    "                    count_S_out += 1\n",
    "            node_F.append(count_S_out)\n",
    "\n",
    "        F_vec.append(node_F)\n",
    "    return F_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c71659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(array1, array2):\n",
    "    intersection = np.sum(np.logical_and(array1, array2))\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42edc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Domain_Fe(DataFram,basis,sel_basis,feature_names):\n",
    "    Fec=[]\n",
    "    for i in range(Number_nodes):\n",
    "    #for i in range(2):\n",
    "        vec=[]\n",
    "        f=DataFram.loc[i, feature_names].values.flatten().tolist()\n",
    "        vec.append(Similarity(f,basis[0]))\n",
    "        vec.append(Similarity(f,basis[1]))\n",
    "        vec.append(Similarity(f,basis[2]))\n",
    "        vec.append(Similarity(f,basis[3]))\n",
    "        vec.append(Similarity(f,basis[4]))\n",
    "        vec.append(Similarity(f,basis[5]))\n",
    "        f.clear()\n",
    "        Fec.append(vec)\n",
    "    SFec=[]\n",
    "    for i in range(Number_nodes):\n",
    "    #for i in range(2):\n",
    "        Svec=[]\n",
    "        f=DataFram.loc[i, feature_names].values.flatten().tolist()\n",
    "        Svec.append(Similarity(f,sel_basis[0]))\n",
    "        Svec.append(Similarity(f,sel_basis[1]))\n",
    "        Svec.append(Similarity(f,sel_basis[2]))\n",
    "        Svec.append(Similarity(f,sel_basis[3]))\n",
    "        Svec.append(Similarity(f,sel_basis[4]))\n",
    "        Svec.append(Similarity(f,sel_basis[5]))\n",
    "        f.clear()\n",
    "        SFec.append(Svec)\n",
    "    return Fec,SFec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94b7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Result(result):\n",
    "    #feature=[]\n",
    "    feature=[]\n",
    "    for i in range(len(x[0])-1):\n",
    "        feature.append(\"{}\".format(i))\n",
    "    l=6\n",
    "    for i in range(l):\n",
    "        feature.append(\"S_{}\".format(i))\n",
    "    for i in range(l):\n",
    "        feature.append(\"I_{}\".format(i))\n",
    "\n",
    "\n",
    "\n",
    "    X=result[feature] # Features\n",
    "    y=result['Class']  # Labels\n",
    "    X_train=X.iloc[Train]\n",
    "    X_test=X.iloc[test_index]\n",
    "    y_train=y.iloc[Train]\n",
    "    y_test=y.iloc[test_index]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler  \n",
    "    scaler = StandardScaler()  \n",
    "    # Don't cheat - fit only on training data\n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    # apply same transformation to test data\n",
    "    X_test = scaler.transform(X_test)  \n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(700,), random_state=1,max_iter=1000, warm_start=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100,\"%\\n\")\n",
    "    #Both.append(metrics.accuracy_score(y_test, y_pred)*100)\n",
    "    return metrics.accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b9b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Result_Spatial(result):\n",
    "    #feature=[]\n",
    "    feature=[]\n",
    "    for i in range(len(x[0])):\n",
    "        feature.append(\"{}\".format(i))\n",
    "\n",
    "\n",
    "\n",
    "    X=result[feature] # Features\n",
    "    y=result['Class']  # Labels\n",
    "    X_train=X.iloc[Train]\n",
    "    X_test=X.iloc[test_index]\n",
    "    y_train=y.iloc[Train]\n",
    "    y_test=y.iloc[test_index]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler  \n",
    "    scaler = StandardScaler()  \n",
    "    # Don't cheat - fit only on training data\n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    # apply same transformation to test data\n",
    "    X_test = scaler.transform(X_test)  \n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(700,), random_state=1,max_iter=1000, warm_start=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy using Spatial Feature only:\",metrics.accuracy_score(y_test, y_pred)*100,\"%\\n\")\n",
    "    #Both.append(metrics.accuracy_score(y_test, y_pred)*100)\n",
    "    return metrics.accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3f34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Result_Domain(result):\n",
    "    feature=[]\n",
    "    l=6\n",
    "    for i in range(l):\n",
    "        feature.append(\"S_{}\".format(i))\n",
    "    for i in range(l):\n",
    "        feature.append(\"I_{}\".format(i))\n",
    "\n",
    "\n",
    "\n",
    "    X=result[feature] # Features\n",
    "    y=result['Class']  # Labels\n",
    "    X_train=X.iloc[Train]\n",
    "    X_test=X.iloc[test_index]\n",
    "    y_train=y.iloc[Train]\n",
    "    y_test=y.iloc[test_index]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler  \n",
    "    scaler = StandardScaler()  \n",
    "    # Don't cheat - fit only on training data\n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    # apply same transformation to test data\n",
    "    X_test = scaler.transform(X_test)  \n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(700,), random_state=1,max_iter=1000, warm_start=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy using Domain Feature:\",metrics.accuracy_score(y_test, y_pred)*100,\"%\\n\")\n",
    "    #Both.append(metrics.accuracy_score(y_test, y_pred)*100)\n",
    "    return metrics.accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7f5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassContrast(result):\n",
    "    feature=[]\n",
    "    for i in range(len(x[0])-1):\n",
    "        feature.append(\"{}\".format(i))\n",
    "    l=6\n",
    "    for i in range(l):\n",
    "        feature.append(\"S_{}\".format(i))\n",
    "    for i in range(l):\n",
    "        feature.append(\"I_{}\".format(i))\n",
    "\n",
    "\n",
    "\n",
    "    X=result[feature] # Features\n",
    "    y=result['Class']  # Labels\n",
    "    X_train=X.iloc[Train]\n",
    "    X_test=X.iloc[test_index]\n",
    "    y_train=y.iloc[Train]\n",
    "    y_test=y.iloc[test_index]\n",
    "\n",
    "    model = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "    # fit the model\n",
    "    num_features_to_select = 12\n",
    "    model.fit(X_train,y_train)\n",
    "    weight=model.get_booster().get_score(importance_type='weight')\n",
    "    sorted_dict = {k: v for k, v in sorted(weight.items(), key=lambda item: (-item[1], item[0]))}\n",
    "    best_features = list(sorted_dict.keys())[:num_features_to_select]\n",
    "\n",
    "    #train using Best feature\n",
    "    X=result[best_features] # Features\n",
    "    y=result['Class']  # Labels\n",
    "    X_train=X.iloc[Train]\n",
    "    X_test=X.iloc[test_index]\n",
    "    y_train=y.iloc[Train]\n",
    "    y_test=y.iloc[test_index]\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler  \n",
    "    scaler = StandardScaler()  \n",
    "    # Don't cheat - fit only on training data\n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)  \n",
    "    # apply same transformation to test data\n",
    "    X_test = scaler.transform(X_test)\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(700,), random_state=1,max_iter=1000, warm_start=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    from sklearn import metrics\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100,\"%\\n\")\n",
    "    return metrics.accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0b4256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run=  0\n",
      "Accuracy: 86.03603603603604 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Accuracy=[]\n",
    "Accuracy_S=[]\n",
    "Accuracy_D=[]\n",
    "Accuracy_CC=[]\n",
    "\n",
    "dataset = Planetoid(root='/tmp/citeseer', name='Citeseer',split='full')\n",
    "data = dataset[0]\n",
    "Number_nodes=len(data.y)\n",
    "label=data.y.numpy()\n",
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)\n",
    "Node_class=[0,1,2,3,4,5,6]\n",
    "for run in range(1):\n",
    "    Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "    label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "    Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "    Data.head()\n",
    "    label=data.y.numpy()\n",
    "\n",
    "    Number_nodes=len(data.y)\n",
    "    fe_len=len(data.x[0])\n",
    "    catagories=Data['class'].to_numpy()\n",
    "    data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "    basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "    sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.1)) \n",
    "                  for i in range(len(df.columns))]\n",
    "                 for df in data_by_class.values()]\n",
    "    dataset = Planetoid(root='/tmp/citeseer', name='Citeseer',split='geom-gcn')\n",
    "    data = dataset[0]\n",
    "    feature_names = [ii for ii in range(fe_len)]\n",
    "    idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "    train_index = np.where(idx_train)[0]\n",
    "    idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "    valid_index = np.where(idx_val)[0]\n",
    "    idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "    test_index = np.where(idx_test)[0]\n",
    "    #num_class=np.max(label)\n",
    "    for idx_test in test_index:\n",
    "        label[idx_test]=6\n",
    "    \n",
    "    Train = np.concatenate((train_index, valid_index))\n",
    "    print('Run= ',run)\n",
    "    F_vec=spatial_two(Node_class, Edgelist,Number_nodes)\n",
    "    #print(F_vec)\n",
    "    x =np.array(F_vec)\n",
    "    k=len(F_vec[0])\n",
    "    feature=[]\n",
    "    for i in range(len(x[0])):\n",
    "        feature.append(\"{}\".format(i))\n",
    "    data_s=pd.DataFrame(x,columns =feature)\n",
    "    data_s.insert(loc=k,column='Class',value=data.y)\n",
    "    data_s.head()\n",
    "    Fec,SFec=Domain_Fe(Data,basis,sel_basis,feature_names)\n",
    "    Fe=[]\n",
    "    for i in range(6):\n",
    "        Fe.append(\"S_{}\".format(i))\n",
    "    Z =np.array(SFec)\n",
    "    data_2 = pd.DataFrame(Z, columns =Fe)\n",
    "    data_2.head()\n",
    "    Fe=[]\n",
    "    for i in range(6):\n",
    "        Fe.append(\"I_{}\".format(i))\n",
    "    y =np.array(Fec)\n",
    "    data1 = pd.DataFrame(y, columns =Fe)\n",
    "    data1.head()\n",
    "    result = pd.concat([data1,data_2,data_s], axis=1)\n",
    "    result.head()\n",
    "    acc_CC=ClassContrast(result)\n",
    "    Accuracy_CC.append(acc_CC)\n",
    "    accuracy=Result(result)\n",
    "    acc_Spa=Result_Spatial(result)\n",
    "    acc_dom=Result_Domain(result)\n",
    "    Accuracy.append(accuracy)\n",
    "    Accuracy_S.append(acc_Spa)\n",
    "    Accuracy_D.append(acc_dom)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1a2671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.860799478724\n",
      "1.9192683932664167\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(Accuracy_CC))\n",
    "print(statistics.stdev(Accuracy_CC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbb7f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.63551759306476\n",
      "4.357975217882893\n",
      "90.44280129185789\n",
      "1.273144108230378\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(Accuracy_S))\n",
    "print(statistics.stdev(Accuracy_S))\n",
    "print(statistics.mean(Accuracy_D))\n",
    "print(statistics.stdev(Accuracy_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f246f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
